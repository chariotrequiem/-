在本练习中，您将实现神经网络的反向传播算法，并将其应用于手写数字识别任务。
在之前的练习中，已经实现了神经网络的前馈传播，并使用Andrew Ng他们提供的权值来预测手写数字。
在本练习中，将自己实现反向传播算法来学习神经网络的参数。
本次的数据与上次作业是一样的，这里不再赘述。
作业中给出了框架，即包含输入层、隐层和输出层的3层框架。神经元数量分别为400、25和10（不包含偏置单元）。

大致步骤：
1.读入数据，并随机选取100个样例进行数据可视化。
   模型展示，这里作业中给出了框架，即包含输入层、隐层和输出层的3层框架。神经元数量分别为400、25和10（不包含偏置单元）。
2.将初始的标签向量y重新定义，展开成一个5000乘10的矩阵，每行只有对应标签的地方为1，其余为0，例如，对某一，表示的数字为4，即，则这一行展开为。
   参数展开，在这里需要提前将参数展开为一维的向量，因为在后面采用fmin_ncg函数训练参数时需要将theta的初始值赋予函数，
   这里的初始值要求是一维向量，因此在后面代价函数和梯度函数的定义中也要注意返回一维的梯度。
3.代价函数，再计算未添加正则项的代价函数，注意这里代价函数以及后面的梯度函数都需要把第一个参数设为theta，也是因为fmin_ncg函数的需要。
   这里代价函数写完后，按照上次作业的前馈神经网络用给出的权重theta1和theta2计算出代价，检查一下代价是否为0.287629。然后再计算添加正则项的代价函数，同样检查代价是否为0.383770。
4.误差逆向传播和梯度，首先计算不带正则项的梯度，然后再和不带正则项的数值梯度函数计算出来的值进行比较，
   如果两个向量差的二范数与向量和的二范数的比值的数量级小于等于e-09即可（梯度检验时要特别注意，因为很容易一点小错误就对不上了，如果有问题，可以看看梯度的第0项与数值梯度第0项的差，
   然后再一步步找，一般来说可能错的地方就在写BP函数以及调用函数的变量赋值过程中，这些都是我掉过的坑）。不带正则项的计算对了之后就开始写带正则项的梯度函数了，
   这里都没有按照吴恩达说的用for循环写，而是直接用矩阵计算，因此惩罚参数的时候只需把参数的第一列设为0然后加上之前的梯度就好了，写完之后依然是梯度检查，
   这里的数值梯度要用正则化的代价函数进行计算。注意计算数值梯度特别特别特别慢，因此在计算完之后就先注释掉吧，免得一不小心又跑了。。。
5.训练权重并计算精度，先随机初始化参数（权重），然后使用牛顿共轭梯度法（opt.fmin_ncg函数）进行训练，这里也稍微有点慢，然后再用训练好的参数进行前馈传播得到预测的y值，
   再与期望的y值进行比较得出精度。
6.最后可视化隐层，将训练好的参数的第一列去掉，即去掉偏置单元的权重，得到的向量代表每个样本输入到每个隐层单元的像素的权重

python相关：
np.concatenate函数可以合并矩阵，axis=0表示纵向相连。
np.random.uniform(-epsilon, epsilon, size)可以随机产生size大小的每个数取值为(-epsilon, epsilon)的矩阵。
注意opt.fmin_ncg的参数传递方式是第一个是theta，然后才是x和y等，因此它里面的代价函数和梯度函数的第一个值也要写成theta。
