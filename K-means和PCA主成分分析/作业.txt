练习：
在本练习中，您将使用k-means聚类算法并且将其应用于压缩图像。
在第二部分中你将使用主成分分析来找到脸部图像的一个低维表示。
第一部分为k-means聚类，你首先从一个2维的样本集开始，他可以帮助你对k-means算法有一个直观的感受。
然后你将使用k-means算法对图像进行压缩，通过减少颜色数量，直到只出现在该图像中最常见的那些颜色。

2）知识点概括：
无监督学习的数据是不带标签的

k-means算法：
原理
1、随机初始化生成k个点，即聚类中心（cluster centroids）
2、重复迭代进行簇分配（cluster assignment）和移动聚类中心（move centroid），直到聚类中心不再改变

输入：k和不带标签的数据集

随机初始化：
随机挑选k个样本作为初始的聚类中心

防止陷入局部最优解的方法：尝试多次（这里举100次迭代）初始化k-means算法并实现，然后选择代价函数最小的那个作为最优解。
这个方法一般对于聚类中心在10个以下比较有效。

关于选择聚类的数量
1、肘部法则（Elbow method）画出代价函数随聚类数量变化的曲线，选择肘部点对应的聚类数量即为较好的（不常用，效果不是很好）
2、看哪个聚类数量能更好的应用于后续目的（downstream purpose）

3）大致步骤：
簇分配，寻找最近的聚类中心。历遍所有数据，返回一个取值为1到K的索引向量。
用初始化的聚类中心[3, 3], [6, 2], [8, 5]测试下，应该得到x的前三个数据分别归属第1 3 2个聚类中心。
计算聚类中心。
运行k-means，设置一个布尔值，若为真则画出每次迭代的图像，以及最后的聚类结果和聚类中心移动的路径；若为假则只输出聚类中心和样本索引向量。
随机初始化聚类中心。尝试以上步骤观察图像。
图像压缩。原图像存储在一个三维数组（height,width,RGB）中，以0~255的整数表示红/绿/蓝的强度，这种编码通常被称为RGB编码。
这里只需要把颜色的数量减少到16种颜色，即设置初始聚类数量为16，
把原始图片的每个像素看作一个数据样本，然后利用k-means算法去找分组最好的16种颜色。
这里需要把像素数据先展开成一个三列的矩阵，然后每行相当于一个数据样本，
对这个样本进行k-means聚类，最后得到一个16个的聚类中心，然后每个数据用它的索引来得到距离最近的聚类中心的RGB编码，
重组成之前shape的一个矩阵，即可得到压缩后的图像。

4）关于Python：
np.argmin函数返回最小值的索引。
plt.plot(mu[:, 4], mu[:, 5], ‘kx–’, markersize=8)中kx—可以直接规定连线的颜色，标记点形状和连线形状等。
matplotlib.image程序包中mpimg.imread函数可以用于读取图片，imsave函数用来保存图片。
.reshape(-1, 3)表示行数由Numpy自动计算，3列。
.set_title可以给子图加标题。
用sklearn中的MiniBatchKMeans可以直接进行k-means回归，
Mini Batch KMeans算法是一种能尽量保持聚类准确性下但能大幅度降低计算时间的聚类模型，
采用小批量的数据子集减少计算时间，同时仍试图优化目标函数，这里所谓的Mini Batch是指每次训练算法时随机抽取的数据子集，
采用这些随机选取的数据进行训练，大大的减少了计算的时间，减少的KMeans算法的收敛时间，但要比标准算法略差一点，
建议当样本量大于一万做聚类时，就需要考虑选用Mini Batch KMeans算法。

